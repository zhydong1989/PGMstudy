随机变量：参数确定后仍然是一个随机变量。例如[0,1]均匀分布对应变量X.
决定变量：参数确定后,值就确定的变量。例一个switch变量: switch(x>2,1,0)
example1: 随机变量 and 决定变量
with pm.Model() as model:
    p_A = pm.Uniform("p_A", 0, 1)
    p_B = pm.Uniform("p_B", 0, 1)
    # Define the deterministic delta function. This is our unknown of interest.
    delta = pm.Deterministic("delta", p_A - p_B)
    obs_A = pm.Bernoulli("obs_A", p_A, observed=observations_A)
    obs_B = pm.Bernoulli("obs_B", p_B, observed=observations_B)

    # To be explained in chapter 3.
    step = pm.Metropolis()  # sampling
    trace = pm.sample(20000, step=step)# sampling 
    burned_trace=trace[1000:] # 1000次后认为稳定，开始取值

example2：bernoulli分布的产生
      pm.Bernoulli("second_flips",0.5,shape=N) 产生的序列默认值为0
      pm.Bernoulli("second_flips",0.5,shape=N,testval=np.random.binomial(1,0.5,N)) 产生bernoulli分布
Norm 分布的产生
      alpha = pm.Normal("alpha", mu=0, tau=0.001, testval=0)
均匀分布的产生:
      p=pm.Uniform("freq_cheating",0,1)
指数分布的产生：
      lambda_1 = pm.Exponential("lambda_1",1)
stats 产生序列
      stats.poisson.rvs
      stats.bernoulli.rvs

example3: variables 数组
Arrays of PyMC3 variables：
   N = 10
   x = np.ones(N, dtype=object)
   with pm.Model() as model:
   for i in range(0, N):
   	x[i] = pm.Exponential('x_%i' % i, (i+1)**2)

example4： accident 的例子:(参数估计?)   _____  对应一般的机器学习方法： logistic 回归
假设: 1.事故发生的概率 P 和 温度(t)的关系： logistic： P(accident)=1/exp(a+b* t)
      2.在某个温度下 事故发生是一个benoulli分布。(与观察的数据产生关联，从而可以学习 a,b)
      3.a,b的先验分布不妨假设为一个正态分布(均值为0, 标准差为 0.001)
数据集: [温度， 事故是否发生]
目标:  a的后验分布，b的后验分布, 以及给定 t的情况下，发生事故的概率(根据a,b 做回归后的 概率点的平均值);  发生事故的概率的95%的分位点

import numpy as np
import scipy.stats as stats
import pymc3 as pm
import theano.tensor as tt
import matplotlib.pyplot as plt
from scipy.stats.mstats import mquantiles
challenger_data=np.genfromtxt("G:/量化投资/概率图模型/challenger_data.csv", skip_header=1,
                                usecols=[1, 2], missing_values="NA",
                                delimiter=",")
challenger_data=challenger_data[~np.isnan(challenger_data[:,1])]

temperature =challenger_data[:,0]
D=challenger_data[:,1]
def logistic(x, beta, alpha=0):
    return 1.0 / (1.0 + np.exp(np.dot(beta, x) + alpha))
'''
获得后验分布，前验分布为正态分布
'''
with pm.Model() as model:
    beta=pm.Normal("beta",mu=0,tau=0.001,testval=0)
    alpha=pm.Normal("alpha",mu=0,tau=0.001,testval=0)
    p=pm.Deterministic("p",1.0 / (1.0 + tt.exp(beta*temperature + alpha)))
    observed = pm.Bernoulli("bernoulli_obs", p, observed=D)
    start = pm.find_MAP()
    step = pm.Metropolis()
    trace = pm.sample(120000, step=step, start=start)
    burned_trace = trace[100000::2]

alpha_samples = burned_trace["alpha"][:, None]  # best to make them 1d 
beta_samples = burned_trace["beta"][:, None]
'''
预测
'''
t = np.linspace(temperature.min() - 5, temperature.max()+5, 51)[:, None]
p_t = logistic(t.T, beta_samples, alpha_samples)
mean_prob_t = p_t.mean(axis=0)#跟定t的平均概率
qs = mquantiles(p_t, [0.025, 0.975], axis=0) #95%置信区间

