随机变量：参数确定后仍然是一个随机变量。例如[0,1]均匀分布对应变量X.
决定变量：参数确定后,值就确定的变量。例一个switch变量: switch(x>2,1,0)
example1: 随机变量 and 决定变量
with pm.Model() as model:
    p_A = pm.Uniform("p_A", 0, 1)
    p_B = pm.Uniform("p_B", 0, 1)
    # Define the deterministic delta function. This is our unknown of interest.
    delta = pm.Deterministic("delta", p_A - p_B)
    obs_A = pm.Bernoulli("obs_A", p_A, observed=observations_A)
    obs_B = pm.Bernoulli("obs_B", p_B, observed=observations_B)

    # To be explained in chapter 3.
    step = pm.Metropolis()  # sampling
    trace = pm.sample(20000, step=step)# sampling 
    burned_trace=trace[1000:] # 1000次后认为稳定，开始取值

example2：bernoulli分布的产生
      pm.Bernoulli("second_flips",0.5,shape=N) 产生的序列默认值为0
      pm.Bernoulli("second_flips",0.5,shape=N,testval=np.random.binomial(1,0.5,N)) 产生bernoulli分布
Norm 分布的产生      alpha = pm.Normal("alpha", mu=0, tau=0.001, testval=0)
均匀分布的产生:
      p=pm.Uniform("freq_cheating",0,1)
指数分布的产生：
      lambda_1 = pm.Exponential("lambda_1",1)
stats 产生序列
      stats.poisson.rvs
      stats.bernoulli.rvs

example3: variables 数组
Arrays of PyMC3 variables：
   N = 10
   x = np.ones(N, dtype=object)
   with pm.Model() as model:
   for i in range(0, N):
   	x[i] = pm.Exponential('x_%i' % i, (i+1)**2)

example4： accident 的例子:(参数估计?)   _____  对应一般的机器学习方法： logistic 回归
假设: 1.事故发生的概率 P 和 温度(t)的关系： logistic： P(accident)=1/exp(a+b* t)
      2.在某个温度下 事故发生是一个benoulli分布。(与观察的数据产生关联，从而可以学习 a,b)
      3.a,b的先验分布不妨假设为一个正态分布(均值为0, 标准差为 0.001)
数据集: [温度， 事故是否发生]
目标:  a的后验分布，b的后验分布, 以及给定 t的情况下，发生事故的概率(根据a,b 做回归后的 概率点的平均值);  发生事故的概率的95%的分位点
模型评价:? 暂缺. 可以使用分离图(seperation plot) 定性分析。  估计发生概率大的 温度 是不是经常发生。
低发生概率的部分(预测) 实际发生的概率小于高发生概率部分(预测)的发生概率（实际观察到的情况)
